# 常问面试题

# 网络

## 1.http和https（应用层）
答：[十分钟搞懂HTTP和HTTPS协议？](https://zhuanlan.zhihu.com/p/72616216)  
1.HTTP协议是超文本传输协议的缩写，英文是Hyper Text Transfer Protocol。它是从WEB服务器传输超文本标记语言(HTML)到本地浏览器的传送协议。  
2.HTTP是一个基于TCP/IP通信协议来传递数据的协议，传输的数据类型为HTML 文件,、图片文件, 查询结果等。

HTTP协议一般用于B/S架构（）。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。  

3.http协议支持客户端/服务端模式，也是一种请求/响应模式的协议。
简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。  
灵活：HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。  
无连接：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接，为了弥补这种不足，产生了两项记录http状态的技术，一个叫做Cookie,一个叫做Session。  
无状态：无状态是指协议对于事务处理没有记忆，后续处理需要前面的信息，则必须重传。  

应用层(HTTP)
HTTP协议工作在应用层，端口号是80。HTTP协议被用于网络中两台计算机间的通信，相比于TCP/IP这些底层协议，HTTP协议更像是高层标记型语言，浏览器根据从服务器得到的HTTP响应体中分别得到报文头，响应头和信息体（HTML正文等），之后将HTML文件解析并呈现在浏览器上。同样，我们在浏览器地址栏输入网址之后，浏览器相当于用户代理帮助我们组织好报文头，请求头和信息体（可选），之后通过网络发送到服务器，，服务器根据请求的内容准备数据。所以如果想要完全弄明白HTTP协议，你需要写一个浏览器 + 一个Web服务器，一侧来生成请求信息，一侧生成响应信息。

从网络分层模型来看，HTTP工作在应用层，其在传输层由TCP协议为其提供服务。所以可以猜到，HTTP请求前，客户机和服务器之间一定已经通过三次握手建立起连接，其中套接字中服务器一侧的端口号为HTTP周知端口80。在请求和传输数据时也是有讲究的，通常一个页面上不只有文本数据，有时会内嵌很多图片，这时候有两种选择可以考虑。一种是对每一个文件都建立一个TCP连接，传送完数据后立马断开，通过多次这样的操作获取引用的所有数据，但是这样一个页面的打开需要建立多次连接，效率会低很多。另一种是对于有多个资源的页面，传送完一个数据后不立即断开连接，在同一次连接下多次传输数据直至传完，但这种情况有可能会长时间占用服务器资源，降低吞吐率。上述两种模式分别是HTTP 1.0和HTTP 1.1版本的默认方式，具体是什么含义会在后面详细解释。

4.http存在的问题：  
可以看到访问的账号密码都是明文传输， 这样客户端发出的请求很容易被不法分子截取利用，因此，HTTP协议不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信息非常不安全。  
请求信息明文传输，容易被窃听截取。  
数据的完整性未校验，容易被篡改。  
没有验证对方身份，存在冒充危险。
  
为了解决上述HTTP存在的问题，就用到了HTTPS。  
HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。  

首先客户端通过URL访问服务器建立SSL连接。  
服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。  
客户端的服务器开始协商SSL连接的安全等级，也就是信息加密的等级。  
客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。  
服务器利用自己的私钥解密出会话密钥。  
服务器利用会话密钥加密与客户端之间的通信。  

5.https存在的缺点：  
HTTPS协议多次握手，导致页面的加载时间延长近50%；  
HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗；  
申请SSL证书需要钱，功能越强大的证书费用越高。  
SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。  

6.http和https的区别：  
　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。  
　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。  
　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。  
　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

7.对称和非对称加密  
对称密钥加密，又称私钥加密，即信息的发送方和接收方用同一个密钥去加密和解密数据。它的最大优势是加/解密速度快，适合于对大数据量进行加密，但密钥管理困难。  
非对称密钥加密，又称公钥加密，它需要使用一对密钥来分别完成加密和解密操作，一个公开发布，即公开密钥，另一个由用户自己秘密保存，即私用密钥。信息发送者用公开密钥去加密，而信息接收者则用私用密钥去解密。  
从功能角度而言非对称加密比对称加密功能强大，但加密和解密速度却比对称密钥加密慢得多。


## 2.TCP

[TCP](https://github.com/Gongyihang/Daily/blob/master/markdown/tcp.md)  


## 3.四层网络结构有哪些？  
1.网络接口层（物理传输通道，可使用多种传输介质传输，可建立在任何物理传输网上。比如光纤、双绞线等等）    
2.网络层（主要功能是完成网络主机中主机间“分组Packet”的传输。四个协议：IP、ICMP、ARP、RARP）  
3.传输层（其主要任务是向上一层提供可靠的端到端服务，确保“报文”无差错、有序、不丢失、无重复地传输。它向高层屏蔽了下层数据通信的细节，是计算机通信体系结构中最关键的一层。包含以下2个重要协议：TCP、UDP）  
4.应用层（应用层确定进程间通信的性质，以满足用户的需要。包含协议譬如：Telnet、FTP、SMTP、POP3、HTTP、NNTP）  
![](https://iknow-pic.cdn.bcebos.com/0df431adcbef7609c40a753122dda3cc7cd99e1f?x-bce-process=image/resize,m_lfit,w_600,h_800,limit_1)

# 编译原理

## 1.编译链接

# 操作系统
## 1.进程和线程的区别
根本区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位。  

a.在开销方面：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

b.所处环境：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行）

c.内存分配方面：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。

d.包含关系：没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

## 2.进程的状态转换，进程的上下文，线程的上下文，线程之间共享

#### a.进程有三态、五态、和七态模型。
三态：按进程在执行过程中的不同情况至少要定义三种状态：

运行（running）态：进程占有处理器正在运行的状态。

进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态； 在多处理机系统中，则有多个进程处于执行状态。

就绪（ready）态：进程具备运行条件，等待系统分配处理器以便运行的状态。

当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。

等待（wait）态：又称阻塞态或睡眠态，指进程不具备运行条件，正在等待某个时间完成的状态。

也称为等待或睡眠状态，一个进程正在等待某一事件发生（例如请求I/O而等待I/O完成等）而暂时停止运行，这时即使把处理机分配给进程也无法运行，故称该进程处于阻塞状态。

![三态](https://s2.ax1x.com/2019/03/31/AryWDI.png)

引起进程状态转换的具体原因如下：  
​
运行态→等待态：等待使用资源；如等待外设传输；等待人工干预。  
​
等待态→就绪态：资源得到满足；如外设传输结束；人工干预完成。  
​
运行态→就绪态：运行时间片到；出现有更高优先权进程。  
​
就绪态—→运行态：CPU 空闲时选择一个就绪进程。  

五态：
五态模型在三态模型的基础上增加了新建态（new）和终止态（exit）。

新建态：对应于进程被创建时的状态，尚未进入就绪队列。

创建一个进程需要通过两个步骤：

1.为新进程分配所需要资源和建立必要的管理信息。

2.设置该进程为就绪态，并等待被调度执行。

终止态：指进程完成任务到达正常结束点，或出现无法克服的错误而异常终止，或被操作系统及有终止权的进程所终止时所处的状态。

处于终止态的进程不再被调度执行，下一步将被系统撤销，最终从系统中消失。

终止一个进程需要两个步骤：

1.先等待操作系统或相关的进程进行善后处理（如抽取信息）。

2.然后回收占用的资源并被系统删除。

![五态](https://s2.ax1x.com/2019/03/31/Aryfbt.png)

引起进程状态转换的具体原因如下：  
​
NULL→新建态：执行一个程序，创建一个子进程。  
​
新建态→就绪态：当操作系统完成了进程创建的必要操作，并且当前系统的性能和虚拟内存的容量均允许。  
​
运行态→终止态：当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结。  
​
运行态→就绪态：运行时间片到；出现有更高优先权进程。  
​
运行态→等待态：等待使用资源；如等待外设传输；等待人工干预。  
​
就绪态→终止态：未在状态转换图中显示，但某些操作系统允许父进程终结子进程。  
​
等待态→终止态：未在状态转换图中显示，但某些操作系统允许父进程终结子进程。  
​
终止态→NULL：完成善后操作。  


七态：三态模型和五态模型都是假设所有进程都在内存中的事实上有序不断的创建进程，当系统资源尤其是内存资源已经不能满足进程运行的要求时，必须把某些进程挂起（suspend），对换到磁盘对换区中，释放它占有的某些资源，暂时不参与低级调度。起到平滑系统操作负荷的目的。

引起进程挂起的原因是多样的，主要有：

1.终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂停使自己的程序静止下来。亦即，使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度，以便用户研究其执行情况或对程序进行修改。我们把这种静止状态成为“挂起状态”。  
2.父进程的请求。有时父进程希望挂起自己的某个子进程，以便考察和修改子进程，或者协调各子进程间的活动。  
3.负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。  
4.操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。  
5.对换的需要。为了缓和内存紧张的情况，将内存中处于阻塞状态的进程换至外存上。

七态模型在五态模型的基础上增加了挂起就绪态（ready suspend）和挂起等待态（blocked suspend）。  

挂起就绪态：进程具备运行条件，但目前在外存中，只有它被对换到内存才能被调度执行。  

挂起等待态：表明进程正在等待某一个事件发生且在外存中。  

![七态](https://s2.ax1x.com/2019/03/31/Ary4VP.png)
引起进程状态转换的具体原因如下：
​
等待态→挂起等待态：操作系统根据当前资源状况和性能要求，可以决定把等待态进程对换出去成为挂起等待态。  
​
挂起等待态→挂起就绪态：引起进程等待的事件发生之后，相应的挂起等待态进程将转换为挂起就绪态。  
​
挂起就绪态→就绪态：当内存中没有就绪态进程，或者挂起就绪态进程具有比就绪态进程更高的优先级，系统将把挂起就绪态进程转换成就绪态。  
​
就绪态→挂起就绪态：操作系统根据当前资源状况和性能要求，也可以决定把就绪态进程对换出去成为挂起就绪态。  
​
挂起等待态→等待态：当一个进程等待一个事件时，原则上不需要把它调入内存。但是在下面一种情况下，这一状态变化是可能的。当一个进程退出后，主存已经有了一大块自由空间,而某个挂起等待态进程具有较高的优先级并且操作系统已经得知导致它阻塞的事件即将结束，此时便发生了这一状态变化。  
​
运行态→挂起就绪态：当一个具有较高优先级的挂起等待态进程的等待事件结束后，它需要抢占 CPU，而此时主存空间不够，从而可能导致正在运行的进程转化为挂起就绪态。另外处于运行态的进程也可以自己挂起自己。  
​
新建态→挂起就绪态：考虑到系统当前资源状况和性能要求，可以决定新建的进程将被对换出去成为挂起就绪态。  
挂起进程等同于不在内存中的进程，因此挂起进程将不参与低级调度直到它们被调换进内存。  

挂起进程具有如下特征：

该进程不能立即被执行  

挂起进程可能会等待一个事件，但所等待的事件是独立于挂起条件的，事件结束并不能导致进程具备执行条件。 （等待事件结束后进程变为挂起就绪态）  

进程进入挂起状态是由于操作系统、父进程或进程本身阻止它的运行。  

结束进程挂起状态的命令只能通过操作系统或父进程发出。  

#### b.进程、线程上下文切换：

什么是上下文切换？  ——任务从保存到再加载的过程就是一次上下文切换。

CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态。

操作系统管理很多进程的执行。有些进程是来自各种程序、系统和应用程序的单独进程，而某些进程来自被分解为很多进程的应用或程序。当一个进程从内核中移出，另一个进程成为活动的，这些进程之间便发生了上下文切换。操作系统必须记录重启进程和启动新进程使之活动所需要的所有信息。这些信息被称作上下文，它描述了进程的现有状态。当进程成为活动的，它可以继续从被抢占的位置开始执行。  

进程的上下文信息包括：进程id、指向可执行文件的指针、栈、静态和动态分配的变量的内存、处理器寄存器。

进程切换分两步  
1.切换页目录以使用新的地址空间。  
2.切换内核栈和硬件上下文。  

对于linux来说，线程和进程的最大区别就在于地址空间。  
对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。所以明显是进程切换代价大  

线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。  

另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。  


对线程唯一或本地的信息包括线程id、处理器寄存器(当线程执行时寄存器的状态，包括程序计数器和栈指针)、线程状态及优先级、线程特定数据(thread-specific data，TSD) 

TSD是一种结构体，包含线程私有的数据和信息。TSD可以包含进程全局数据的私有副本，还可以包含线程的信号掩码。信号掩码用来识别特定类型的信号，这些信号在发送给进程时不会被该线程接收。否则，如果操作系统给进程发送一个信号，进程的地址空间中的所有线程也会接收到那个信号。线程会接收所有没有被掩码遮蔽的信号。  

线程与它所属的进程共享代码段和栈段。它的指令指针指向进程的代码段的某个位置，是下一条可执行的线程指令，而且栈指针指向进程栈中线程的栈的顶部位置。线程还可以访问任何环境变量。进程的所有资源(例如文件描述符)都将与线程共享。

![进程线程上下文切换](https://img-blog.csdnimg.cn/20200406224342281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ZqaGdoamdoag==,size_16,color_FFFFFF,t_70)

调度  
进程调度，切换进程上下文，包括分配的内存，数据段，堆栈段等  
线程调度，切换线程上下文，主要切换堆栈，以及各寄存器（同个进程里的线程 堆栈不同）  
协程，（轻量级线程） 每个协程都自带一个栈，协程就是一个函数和这个函数运行时数据的栈

## 3.I/O复用技术select/poll/epoll区别，问select为啥限制1024
C10K问题：  
随着互联网的普及，应用的用户群体几何倍增长，此时服务器性能问题就出现。最初的服务器是基于进程/线程模型。新到来一个TCP连接，就需要分配一个进程。假如有C10K，就需要创建1W个进程，可想而知单机是无法承受的。那么如何突破单机性能是高性能网络编程必须要面对的问题，进而这些局限和问题就统称为C10K问题，最早是由Dan Kegel进行归纳和总结的，并且他也系统的分析和提出解决方案。  
本质：C10K问题的本质上是操作系统的问题。对于Web 1.0/2.0时代的操作系统，传统的同步阻塞I/O模型处理方式都是requests per second。当创建的进程或线程多了，数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞，进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是C10K问题的本质。  

可见, 解决C10K问题的关键就是尽可能减少这些CPU资源消耗。  

C10K问题的解决方案
从网络编程技术的角度来说，主要思路：  
1.每个连接分配一个独立的线程/进程  

2.同一个线程/进程同时处理多个连接  

#### 每个进程/线程处理一个连接  

该思路最为直接，但是申请进程/线程是需要系统资源的，且系统需要管理这些进程/线程，所以会使资源占用过多，可扩展性差  

#### 每个进程/线程同时处理 多个连接(I/O多路复用)  
[一文读懂I/O多路复用技术](https://www.jianshu.com/p/9cadb8b358d7)  

select方式：使用fd_set结构体告诉内核同时监控那些文件句柄，使用逐个排查方式去检查是否有文件句柄就绪或者超时。该方式有以下缺点：文件句柄数量是有上线的，逐个检查吞吐量低，每次调用都要重复初始化fd_set。  
poll方式：该方式主要解决了select方式的2个缺点，文件句柄上限问题(链表方式存储)以及重复初始化问题(不同字段标注关注事件和发生事件)，但是逐个去检查文件句柄是否就绪的问题仍然没有解决。  
epoll方式：该方式可以说是C10K问题的killer，他不去轮询监听所有文件句柄是否已经就绪。epoll只对发生变化的文件句柄感兴趣。其工作机制是，使用"事件"的就绪通知方式，通过epoll_ctl注册文件描述符fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd, epoll_wait便可以收到通知, 并通知应用程序。而且epoll使用一个文件描述符管理多个描述符,将用户进程的文件描述符的事件存放到内核的一个事件表中, 这样数据只需要从内核缓存空间拷贝一次到用户进程地址空间。而且epoll是通过内核与用户空间共享内存方式来实现事件就绪消息传递的，其效率非常高。但是epoll是依赖系统的(Linux)。  
异步I/O以及Windows，该方式在windows上支持很好，这里就不具体介绍啦。

简单说一下BIO，说一下它的缺点：
BIO中的B，表示的是blocking的意思，就是阻塞。作为服务端开发，我们使用server socket绑定完端口号之后，我们会监听该端口，等待accept事件，accept会阻塞当前主线程，当我们收到accept事件时，程序就会拿到一个客户端与当前服务端连接的socket，针对这个socket我们可以进行读写，但是呢，这个socket读写方法都是会阻塞当前线程的，一般我们会使用多线程的方式来进行c/s交互，但是这样就很难解决C10K问题(比如说1w个客户端就需要1w个线程去支持，这样的话且不说cpu肯定会爆炸了，线程上下文切换，也会把机器负载给拉飞了)  

NIO靠什么解决C10K？  
比如我们调用NOI的api，它提供一套非阻塞的接口，这样就不需要我们为每一个c/s长连接保留一个单独的处理线程了，阻塞IO之所以需要socket长连接，指定一个线程，就是因为它阻塞，现在这个NIO API具备非阻塞特性了，就可以用一个线程去检查n个socket，比如nio包提供了一个选择器selector，我们把检查的socket注册到这个selector中，然后主线程阻塞在selector#select方法里，当选择器发现某个socket就绪了，就会唤醒主线程，然后咱们可以通过selector获取到就绪状态的socket进行相应的处理。  

操作系统kernel提供的select函数实现原理：
每次调用kernel#select函数，它都会涉及到用户态/内核态的切换，还需要传递需要检查的socket集合，其实就是检查fd（文件描述符id），因为程序都是运行在linux或者unix操作系统上，这种操作系统上，一切皆文件，socket也不例外，这里传递的fd其实就是文件系统中对应socket生成的文件描述符，socket函数被调用以后，首先会按照fd集合，去检查内存中socket套接字状态，这个复杂度是O（N）的，检查完一遍之后，如果有就绪状态的socket，那么直接返回，不会阻塞当前调用线程。否则，就说明当前指定fd集合对应的socket没有就绪状态的，那么就需要阻塞当前调用线程了，直到有某个socket有数据之后，才唤醒线程。
select函数去监听socket的时候，socket数量有没有什么限制？  
默认最大可以监听1024个socket（实际要小于1024）
为什么？  
fd_set是select函数的参数之一，因为fd_set这个结构它是一个bitmap位图结构，
这个位图结构就是一个长的二进制数，类似于0101这种，这个bitmap默认长度是1024个bit，要想修改这个长度的话，非常麻烦，需要重新编译操作系统内核（针线活，一般人搞不定）。另一点，默认给的1024个bit，它是处于性能的考虑吧。因为select函数检查就绪状态的socket后，它做了两件事，第一件事跑到就绪状态的socket对应的filedescriptor（fd文件）中设置一个标记，标记一个mask，表示当前fd对应的socket就绪了，第二件事就是返回select函数，对应的也就是唤醒线程，返回一个int结果值，表示有几个socket处于就绪状态，具体的哪个socket就绪，java程序是不知道的。所以接下来又是一个O（N）的系统调用，检查fd，fd_set集合中每一个socket的就绪状态，其实就是检查文件系统中指定socket的文件描述符状态，涉及到用户态-内核态来回切换，如果bitmap再大，就需要更多的系统调用，开销就非常非常大了，系统调用涉及到参数的数据拷贝，如果数据太庞大，它也不利于系统调用的速度。  
假设select函数第一遍O（N）去检查时未发现就绪状态的socket，然后假设过了一会之后，有某一个socket它就绪了。那这个select函数它是怎么发现的呢？难道这个select函数它在底层kernel内一直是占着cpu去轮询去检查这些socket吗？  
操作系统调度和操作系统中断，先说调度，cpu（单核心）同一时刻，它只能运行一个进程，操作系统最主要的任务就是系统调度嘛，就是有n个进程，然后让n个进程在cpu上切换执行，未挂起的进程都在工作队列内，都有机会获取到cpu执行权，挂起的进程，就会从这个工作队列内移除出去，反映到程序层面就是线程阻塞了，linux系统线程其实就是轻量级的进程，然后咱们再说一下操作系统中断，这个非常重要，比如咱们用键盘打字，如果cpu正执行着其他程序，一直不释放，那咱们这个打字没法打了，但是咱们知道，不是这样的，因为有了系统中断的存在，我们按下一个键了以后，会给主板发送一个电流信号，主板感知到以后会触发cpu中断，所谓中断，其实就是让cpu正在执行的进程先保留程序上下文，然后避让出cpu，给中断程序让道，中断程序就会拿到cpu执行权限，进行相应代码执行，比如键盘的中断程序，他就会执行输出逻辑等等。  
咱在回到这个问题上，select函数，第一遍轮询，它没有发现就绪状态的socket，他就会把当前进程，保留给需要检查的socket的等待队列中，也就是这个socket结构，有三块核心区域，分别是读缓存，写缓存还有这个等待队列，这个select函数，它把当前进程保留到每个需要检查的socket#等待队列之后，就会把当前进程从工作队列移除了，移除之后，其实就是挂起当前进程了，select函数也就不会再运行了嘛，这个阶段完了，之后，然后咱们再说下一个阶段。假设咱们客户端往当前服务器发送了数据，数据通过网线到网卡，网卡再到DMA硬件的这种方式直接将数据写到内存里头，整个过程cpu是不参与的，当数据完成传输以后，它会触发网络数据传输完毕的中断程序了，这个中断程序它会把cpu正在执行的进程给顶掉，然后cpu就会执行咱这个中断程序的逻辑了。大概是这样，根据内存中有的数据包，然后分析出来数据包是哪个socket的数据，tcp/ip协议，它又保证传输的时候是有端口号的，数据包是有端口号的，然后根据端口号就能找到socket实例，找到socket实例以后，就把数据导入到socket的读缓冲区里头，导入完成以后，它就开始去检查socket的等待队列，是不是有等待者？如果有的话，咱就把等待者移动到工作队列，中断程序到这一步就执行完了，咱们的进程又回归到工作队列了，又有机会获取到cpu时间片了，然后这个当前进程执行select函数再检查，再次检查，就发现有就绪的socket了，它就会给就绪的socket的fd文件描述符打标记，然后select函数就执行完了，它返回到java程序层面，就涉及到内核态-用户态的转换，后面的事情就是轮询检查每一个socket的fd是否被打标记，然后处理被打标记的socket就ok了。

poll函数和select函数的区别  
最大区别就是传参不一样了，select使用的是bitmap，表示需要检查的socket集合。  
poll使用的是数组结构，表示需要检查的socket集合。主要就是为了解决bitmap长度是1024这个问题，poll使用数组就没有这个限制了，他就可以让咱们线程监听超过1024个socket限制。
epoll产生的背景是什么？  
epoll主要是为了解决select和poll函数的缺陷吧，我们先说一下select和poll他俩共有的缺陷。
第一个是这两个函数每次调用都需要我们提供给它所有的需要监听的socket文件描述符集合，而且咱们程序主线程是死循环调用select/poll函数的，这里面涉及到用户空间数据到内核态空间拷贝的过程，这个过程是比较耗费性能的，但是咱们监听socket集合，数据变化非常小，可能每次就1~2个socket_fd需要更改，但是没有办法，因为select和poll函数只是一个很单纯的函数，他在kernel层面，不会保留任何数据信息，所以说每次调用都进行数据拷贝了，这是第一个缺陷。  
第二个缺陷，select和poll函数的返回值是个int整型值，只能代表有几个socket就绪或者是有错误了，没办法表示出具体是哪一个socket就绪了，这就导致咱们程序被唤醒之后，它还需要新的一轮调用去检查哪个socket是就绪状态，然后在进行socket数据处理逻辑，在这里走了不少弯路。因为在系统调用需要涉及到用户态和内核态的来回切换，这个缺陷更严重了。  
主要缺陷就是这些，这也是epoll的产生背景，主要目的是为了解决这两个问题。  
epoll是如何设计的？  
为了提升效率就要解决这两个问题，第一个问题是函数调用参数拷贝问题，第二个是系统调用返回后不知道哪些socket就绪的问题，解决这两个问题，就需要epoll函数在内核空间内，它有一个对应的数据结构去存储一些数据，这个数据结构其实就是eventpoll对象，它可以通过一个系统函数epoll_create()去创建，创建完成之后，系统函数返回一个eventpoll对象的id，相当于我们在内核开辟了一小块空间，并且我们也知道这块空间的位置。eventpoll的结构主要是两块区域，其中一块是存放需要监听的socket_fd描述符列表，另一块区域是就绪列表，存放就绪状态的socket信息。另外还提供两个函数，一个是epoll_ctl函数，另外一个是epoll_wait函数。epoll_ctl它可以根据eventpoll_id区增删改内核空间上的eventpoll对象的检查列表（即关注的socket信息）。
去增加或者修改需要检查的socket文件描述符，epoll_wait()，它主要的参数是eventpoll_id表示此次系统调用需要检测的socket_fd集合，是eventpoll中已经定好的那些socket信息，epoll_wait函数，他默认情况下会阻塞调用线程，直到eventpoll中关联的某个或者某些个socket就绪以后，epoll_wait()才会返回。

eventpoll中药存放需要监视的socket集合信息，这个存放socket集合信息用的是什么数据结构？  
红黑树结构，因为socket集合信息经常会有增删改查的需求，这个需求，红黑树一定是最适合的了，他能保持一种相对稳定的查找效率，复杂度是O(logN)。


# 算法

## 1.大数排序
2g的内存，id唯一，整数不重复，如何对它进行排序（提示分治思想或者考虑比特）  
 
# 语言之C++

## 1.指针和引用的区别

## 2.多态的实现

## 3.STL相关
vector底层原理、扩容原理，unorder_map底层实现，红黑树查询复杂度

## 4.左值和右值


